---
title: "**Goodreads Project**"
author: "Hananel Mandeleyl, Dmitry Zalyalyeyev"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tibble.width = Inf)
options("scipen" = 100)
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggplot2)
library(reshape2)
library(leaps)
library(car)
library(gridExtra)
locale(date_format = "%AT")
```

&nbsp;

***

## Phase 1 | **Data Import**

***

First, we shall import our dataset using the `read_delim()` function.  
The reason we chose using the `read_delim()` function is When you run `read_delim()` it prints out a column specification that gives the name and type of each column:   
  
```{r import}
data <- read_delim("books.csv", ",", quote = "\"")
```

&nbsp;

We can see a few warnings, but we will ignore them for now and get back to them during the tidying phase.  
For now, we'll just get to know our data better.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **1.1. What are we dealing with?**

Let's take a sneak peak first:

```{r sneak peak, echo = FALSE}
data[1:3, ] %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

Our dataset contains information about 11,127 books from the *Goodreads* online catalog.  

> **Goodreads** is a social cataloging website that allows individuals to search freely its database of books, annotations, quotes, and reviews. Users can sign up and register books to generate library catalogs and reading lists.

&nbsp;

#### **1.2. Variables**

Our dataset consists of 12 variables:  

1. `bookID`: Book ID.  
2. `title`: Title.  
3. `authors`: Authors.  
4. `average_rating`: Average rating.  
5. `isbn`: ISBN number.  
6. `isbn13`: ISBN13 number.  
7. `language_code`: Language code.  
8. `num_pages`: Number of pages.
9. `ratings_count`: Ratings count.  
10. `text_reviews_count`: Text reviews count.  
11. `publication_date`: Publication date.  
12. `publisher`: Publisher.  

We are dealing with more than one kind of variables; we have categorical variables, numerical variables, some are discrete and some are continuous, some are unique to each observation and some are not.  
On our project we will research how different characteristics influence a title's average score, and how big an effect each has on it.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **1.3. Some early statistics and insights**

Even at such an early stage it is wise to get some raw insights about the data. A `summary()` will be great:

```{r summary}
summary(data)
```

&nbsp;

It looks like we have everything we need to explore and tidy-up the data.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

***

## **Phase 2** | Data Tidying

***

In this phase we would like to clean the data up and address any issues which came up during the import phase. Those do not require data transformations per se, but rather cleaning and rearrangement (e.g. entry shifting and text leaks).   

We can see that our data is pretty clean as it is; each row is an observation of its own, and each column is an understadable, intuitive variable; but all that doesn't mean it's flawless.  

&nbsp;

#### **2.1. Row shifting and text leakage fix**

Let's deal with those warnings we got while importing the data.  
Fortunately, we have the `problems()` function, which makes it really easy to identify problematic entries:

```{r initial problems check}
data %>%
  problems %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

We've got a few problematic entries, but notice that they all come from 4 specific rows.  
Another thing to notice is that while importing we got another warning --- there are 13 columns identifed while only 12 were expected, which suggests we are dealing with a right shift of the said rows.  

After a manual review we've narrowed the list of errors to:

Row  | Error
---- | --------------------------
3349 | Text leakage, row shifting 
4703 | Text leakage, row shifting
5878 | Text leakage, row shifting
8980 | Text leakage, row shifting

After careful consideration we've decided that the best way to fix the errors would be applying manual row reconstruction, as R doesn't read problematic entries when it encounters parcing problems, but rather fills them with NA values, resulting in information loss.  
Let's import the fixed dataset and make sure all the warnings are resolved:

```{r row shifting fix and check, results = "hide"}
data <- read_delim("books update 1 rows.csv", ",", quote = "\"")
```

```{r problems check}
cat("The number of problems found:", data %>% problems %>% nrow)
```

**Success!** No more row shifting and text leakage.

&nbsp;

#### **2.2. Nonuniformity of publisher names**

We were suspicious that publisher names will be spelled nonuniformly across different titles, and so was the case.
A manual fix has been applied for efficiency reasons.  
Let's load a fixed version and continue:

```{r publisher names fix, results = "hide"}
data <- read_delim("books update 2 publishers.csv", ",", quote = "\"")
```

&nbsp;

#### **2.3. Dialect-specific language codes grouping**

Although distinguishing between different English dialects in the `language_code` variable can add a lot of valuable information to the study, we've chosen to combine all the English dialects except an old version called Middle English (1,100--1,500) to a single value --- **"eng"**.  
The reason is that in addition to dialect-specific English language codes (e.g. "en-GB"), the `language_code` variable also contains an ambiguous "eng" value, what might result in an inaccurate distribution of dialect influence, and in turn lead to an untruthful representation of it.   
We've written simple code to convert dialect-specific language codes into generic "eng" entries:

```{r language code fix}
before <- data$language_code[6]

data$language_code[grepl("en", data$language_code, fixed = TRUE) &
                     !grepl("eng", data$language_code, fixed = TRUE) &
                     !grepl("enm", data$language_code, fixed = TRUE)] <- "eng"

after <- data$language_code[6]
```

Let's test it by printing the values of `before` and `after`, which contain the value observation 6 before and after the fix:

```{r test 1, echo = FALSE}
cat("Language code of observation 6 before the fix:", before,
    "\nLanguage code of observation 6 after the fix:", after)
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **2.4. Publication date format fix**

We noticed that the date format is nonuniform (e.g. some are *mm/dd/yyyy* while others are *m/dd/yyyy*).  
The following code fills in the missing digit where required and changes the format to a local one; we'll test it 

```{r publication date fix}
before <- data$publication_date[1]

str_to_date <- function(string) {
  if (nchar(string) < 10) {
    return(paste0("0", string) %>%
             as.Date(format = "%m/%d/%Y") %>%
             format("%d/%m/%Y"))
  } else {
    return(string %>%
             as.Date(format = "%m/%d/%Y") %>%
             format("%d/%m/%Y"))
  }
}

data$publication_date <- sapply(data$publication_date, str_to_date)

after <- data$publication_date[1]
```

Let's test it by printing the values of `before` and `after`, which now hold the value observation 1 before and after the fix:

```{r test 2, echo = FALSE}
cat("Publication date of observation 1 before the fix:", before,
    "\nPublication date of observation 1 after the fix:", after)
```

**Success!**

&nbsp;

#### **2.5. Columns rearrangement**

As our target variable is the `average_rating` variable, we would like to rearrange the dataset so that it would appear in the last column.  
Also, we would like to fix some names (i.e remove whitespaces from column names), and group all the categorical variables on the left and all the numerical varibales on the right:

```{r average rating rearrangement}
names(data) <- gsub(" ", "", names(data))

data <- data[, c("bookID", "title", "authors", "publisher", "language_code", "isbn", "isbn13", "publication_date", "num_pages", "ratings_count", "text_reviews_count", "average_rating")]
```

&nbsp;

Looks like our dataset is clean and ready for the next phase:

```{r tidying done}
data[1:3, ] %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

***

## Phase 3 | **Understanding the data**

***

### Part A | **Transforming variables**

&nbsp;

In this section, different transformations will applied to the data in order to extract the most useful information from the data, while removing the unnecessary parts to maintain the lowest dimension possible. 

&nbsp;

#### **3.A.1.** `NA` **handling**

Of all the `NA` entries we would first like to discuss the most important ones --- where `average_rating == NA`. As we previously mentioned, the `average_rating` variable is our target, hence observations without it are ununseful to us as training samples:

```{r na average rating rows removal}
data <- data[!is.na(data$average_rating), ]
```

Regarding the rest, we first need to check how bad is the situation anyway.  
Here are the observations containing at least one `NA` entry:

```{r na check}
data[rowSums(is.na(data)) > 0,] %>%
  head %>%
  kable("html") %>%
  kable_styling(font_size = 9)

which(is.na(data), arr.ind = TRUE)
```

The dates that were entered don't exist. After quick search of the *goodreads* website we got the correct publication dates (October/June 30th instead of 31st), so thankfully no removals are needed. Let's fix the entries and check:

```{r filling na}
data[unique(which(is.na(data), arr.ind = TRUE)[, 1]),
     unique(which(is.na(data), arr.ind = TRUE)[, 2])] <- as.Date(c("10/31/2000", "06/30/1982"), format = "%m/%d/%Y") %>% format("%d/%m/%Y")

cat("Amount of NA entries:", sum(is.na(data)))
```
Great! Our data is free from `NA` entries.

&nbsp;

#### **3.A.2. Removal of observations with a small ratings sample size**

The `average_rating` is averaged between `ratings_count` reviews, so we've decided that observations with `ratings_count << 30` will be regarded as non-representative and will be removed.  
This is because their `average_rating` has been determinded using an insufficient sample size.

```{r small ratings_count rows removal}
data <- data[data$ratings_count >= 30, ]
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.A.3. ISBN and ISBN13**

> The **International Standard Book Number** (**ISBN**) is a numeric commercial book identifier which is intended to be unique.  
An ISBN is assigned to each separate edition and variation of a publication. For example, an e-book, a paperback and a hardcover edition of the same book will each have a different ISBN.

In other words, the `isbn` and `isbn13` (13-digit ISBN format) variables aren't really numerical --- they are **categorical**, as we can clearly see in the `summary()` we've printed earlier.

Provided that each observation is a publication of its own, we can safely presume that every `isbn`, `isbn13` and `bookID` entry will be unique for each observation.  
Hence, the `isbn` and `isbn13` doesn't offer any distinction between observations more than `bookID` does.

For the reason above we have decided to remove both the `isbn` and the `isbn13` variable,  and convert the `book_id` variable to be strictly categorical:

```{r remove isbn and isbn13}
# Dropping the isbn and isbn13 variables
drops <- c("isbn","isbn13")
data <- data[ , !(names(data) %in% drops)]

# Converting the bookID variable to categorical
data$bookID <- sapply(data$bookID, toString)
```

Let's have a look:

```{r test}
data %>%
  head %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

Beautiful, we can see the `bookID` column is left-aligned, suggesting it is now a categorical variable, as opposed to numerical columns which are right-aligned.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.A.4. Title length transformation**

The title might have a substantial contribution to a publication's score. We are influenced by marketing, social conventions and more.  
Yet, due to performance considerations, we aren't going to decompose the titles, nor search for common phrases or buzzwords.  
If so, you might wonder why the `title` variable wasn't removed along with `isbn` and `isbn13`.  
The reasons are:

1. The `title` variable isn't unique per observation as `isbn` and `isbn13`.
2. There is undelying information hidden in the title.

An example for excellent information we can extract from the title is its length. We think that a title's length may affect the average score --- different title lengths can be associated with different genres, levels, time periods and more. We even suspect there might be a title length "sweet spot".
This is why we have decided to add a `title_len` variable.

**Note:** We are discussing the different influences on a publication's average rating specifically on *goodreads*, meaning that we are taking the length of the publications' title **as it appears on the website**. 

``` {r title_len addition}
# Adding the title length variable
data$title_len <- sapply(data$title, nchar)

# Column rearrangement
data <- data[, c("bookID", "title", "authors", "publisher", "language_code", "publication_date", "title_len", "num_pages", "ratings_count", "text_reviews_count", "average_rating")]

data %>%
  head %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

&nbsp;

#### **3.A.5. From publication date to time since publication**

The `publication_date` variable is categorical. However, we would like to transform it into a numeric variable which will be more useful in our further analysis --- hence the “time since publication” variable. We will do so by calculating the number of weeks that have passed since each book’s publication date until August 5th, 2020, i.e. the dataset's date of approval:

```{r time since publication}
data$publication_date <- as.numeric(rep(as.Date("05/08/2020", format = "%d/%m/%Y"), times = nrow(data)) - as.Date(data$publication_date, format = "%d/%m/%Y")) / 7

# Variable name change
names(data)[names(data) == "publication_date"] <- "weeks_since_publication"
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.A.6. Outliers removal**

Outliers can negatively affect our research in multiple ways.  
It it especially important to remove outliers now before performing any scaling on the data.  
After careful consideration and review of numerical variables' boxplots, we've came to the conclusion that for our dataset, statistical outliers are'nt necessarily illogical.  
For example, the following plot suggests that a 200-letters title is an obvious outlier:

```{r fake outlier 1, fig.align = "center", fig.width = 7, fig.height = 6}
boxplot(data$title_len)
```

But as we can see, **those are** titles:

```{r fake outlier 2}
data[data$title_len >= 200, ] %>%
  head %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

A better indication of outliers in our dataset would be the minimum and maximum value of each numerical variable:

```{r real outliers check}
min_max_num_vars <- tibble(min_max = c("Minimum", "Maximum"),
                           weeks_since_publication = c(min(data$weeks_since_publication), max(data$weeks_since_publication)),
                           title_len = c(min(data$title_len), max(data$title_len)),
                           num_pages = c(min(data$num_pages), max(data$num_pages)),
                           ratings_count = c(min(data$ratings_count), max(data$ratings_count)),
                           text_reviews_count = c(min(data$text_reviews_count), max(data$text_reviews_count)),
                           average_rating = c(min(data$average_rating), max(data$average_rating))) %>% column_to_rownames(var = "min_max")

min_max_num_vars %>%
  kable("html") %>%
  kable_styling(font_size = 9)
```

After careful review of the values and the dataset we can confirm that no additional outlier removal is necessary as all numbers make sense.

**Note:** We found out that among the authors presented in the dataset there is a “NOT A BOOK” value.  
We have examined the relevant entries, and it appears that those refer to audio content. Therefore, we have decided to leave those entries in the dataset, as was the case with other audiobooks that were mentioned in the dataset.

&nbsp;

#### **3.A.7. Numerical variables scaling**

And lastly before visualizations, ince a scaled version of the data might be valuable for our further analysis, we would thus like to create 2 versions of the dataset in which all the numeric variables appear scaled --- with normal scaling in one, and min-max scaling in the other:

```{r scaling}
numer_vars <- c("weeks_since_publication", "title_len", "num_pages", "ratings_count", "text_reviews_count")

# Normal scaling
norm_scaled_data <- data
norm_scaled_data[, numer_vars] <- scale(norm_scaled_data[, numer_vars])

## Varible name changes
norm_scaled_data <- norm_scaled_data %>%
  rename(scaled_weeks_since_publication = weeks_since_publication,
         scaled_title_len = title_len,
         scaled_num_pages = num_pages,
         scaled_ratings_count = ratings_count,
         scaled_text_reviews_count = text_reviews_count)

# Min-max scaling
min_max_scaler <- function(x) {(x - min(x)) / (max(x) - min(x))}
min_max_scaled_data <- data
min_max_scaled_data[, numer_vars] <- min_max_scaler(min_max_scaled_data[, numer_vars])

## Varible name changes
min_max_scaled_data <- min_max_scaled_data %>%
  rename(scaled_weeks_since_publication = weeks_since_publication,
         scaled_title_len = title_len,
         scaled_num_pages = num_pages,
         scaled_ratings_count = ratings_count,
         scaled_text_reviews_count = text_reviews_count)
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

***

### Part B | **Visualizing**

&nbsp;

Visual information is incredibly valuable to us, and we will try to provide some good examples for it.

&nbsp;

#### **3.B.1. Correlation heatmap**

The first visualization that we would like to introduce is the correlation between any two of the predictors. In order to do that, we will use our `norm_scaled_data` to produce we used a correlation heatmap:

```{r cor heatmap, fig.align = "center", fig.width = 8, fig.height = 7}
scaled_numer_vars <- c("scaled_weeks_since_publication", "scaled_title_len", "scaled_num_pages", "scaled_ratings_count", "scaled_text_reviews_count", "average_rating")

ggplot(melt(cor(norm_scaled_data[, scaled_numer_vars])), aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Variable 1", y = "Variable 2", title = "Numerical variables correlation heatmap") +
  scale_fill_gradient2(low = "red", high = "blue", mid = "black", 
   midpoint = 0, limit = c(-1,1), space = "Lab")
```

Unsurprisingly, the `scaled_ratings_count` and `scaled_text_reviews_count` variables are strongly correlated, while the correlations of the rest are only weak to moderate, but maybe still statistically significant.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.B.2. Number of publications by language**

In order to better understand which books our dataset stands for we have checked what is the amount of books published by their language.

We first looked at the number of books in each language

```{r books per language, fig.align = "center", fig.width = 7, fig.height = 4}
language <- forcats::fct_infreq(data$language_code)
ggplot(data, aes(x = language)) +
  geom_bar(mapping = aes(fill = language, color = language), show.legend = FALSE) +
  labs(y = "Count", x = "Language code", title = "Number of publications by language group") +
  theme(axis.text.x = element_text(angle = 90))
```

From the graph above we deduce that the number of books in the datatset that were published in English is significantly higher than those that were published in any other language. This is an important observation as it implies that the relevance of the results of our research might be predominantly limited to the English speaking community, and more so --- does not take into account people’s preferences in regards to the books that were published in other languages. We aknowledge the fact that such limitation inherently exists as we explore the data taken from a website the language of which is English.

&nbsp;

In order to explore the amount of books published in each language besides English, we turn to a graph that refers to all books in the dataset, except those published in English:

```{r books per lang wo eng, fig.align = "center", fig.width = 7, fig.height = 4}
non_eng <- filter(data, language_code != "eng")
Language <- forcats::fct_infreq(non_eng$language_code)
ggplot(non_eng, aes(x = Language)) +
  geom_bar(mapping = aes(fill = Language, color = Language), show.legend = FALSE) +
  labs(y = "Count", x = "Language code", title = "Number of publications by language group (non-English)") +
  theme(axis.text.x = element_text(angle = 90))
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.B.3. Average rating by language group boxplots**

We now turn to better understand the ratings of books written in a particular language, compared to others:

```{r langs boxplot, fig.align = "center", fig.width = 8, fig.height = 7}
language <- forcats::fct_infreq(data$language_code)
avg_rating <- data$average_rating
ggplot(data) +
  geom_boxplot(mapping = aes(x = language, y = avg_rating)) +
  labs(y = "Average rating", x = "Language code", title = "Average rating boxplots of different language groups, sorted by sample size")
```

The boxplot graph provides us an interesting inference: the median average rating among each of the four most common languages is very similar --- almost 4 points.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.B.4. Average rating distribution**

We would like to check whether the average rating distributes normally.  
For this purpose we will use the normal Q-Q plot:

```{r qqplot all langs, fig.align = "center", fig.width = 5, fig.height = 3.8}
ggplot(data, aes(sample = average_rating)) +
  stat_qq(shape = 21, size = 2) +
  stat_qq_line() +
  labs(x = "Theoretical quantiles", y = "Sample quantiles", title = "Normal quantile-quantile plot of average rating")
```

&nbsp;

In addition, we would like to check whether the average rating distributes differently for English and non-English titles:

```{r qqplot eng and non-eng, fig.align = "center", fig.width = 12, fig.height = 4.5}
eng <- data %>% filter(language_code == "eng")
non_eng <- data %>% filter(language_code != "eng")

eng_qq <- ggplot(eng, aes(sample = average_rating)) +
  stat_qq(shape = 21, size = 2) +
  stat_qq_line() +
  labs(x = "Theoretical quantiles", y = "Sample quantiles", title = "Normal Q-Q plot of average rating (English titles)")

non_eng_qq <- ggplot(non_eng, aes(sample = average_rating)) +
  stat_qq(shape = 21, size = 2) +
  stat_qq_line() +
  labs(x = "Theoretical quantiles", y = "Sample quantiles", title = "Normal Q-Q plot of average rating (non-English titles)")

grid.arrange(eng_qq, non_eng_qq, ncol = 2)
```

&nbsp;

Curiously enough, non-English titles' average rating distribution appears to be approximately more normal than those of English titles, yet keep in mind that the former group's sample size is several orders of magnitude smaller than the latter's, thus only has small effect on the general curve. 

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

Now, we would like to see exactly how the average rating distributes:

```{r avg rating pdf, fig.align = "center", fig.width = 6, fig.height = 4}
avg_rating <- data$average_rating
ggplot(data) +
  stat_density(aes(x = avg_rating), geom = "line", position = "identity") +
  labs(y = "Density", x = "Average rating", title = "PDF of average rating") +
  geom_vline(aes(xintercept = mean(average_rating)), linetype = "dashed", color = "dark grey")
```

&nbsp;

Let's see how each language group's rating distributes seperately:

```{r avg ratings by lang pdf, fig.align = "center", fig.width = 6, fig.height = 4.6}
is_eng <- filter(data, language_code == "eng")
non_eng <- filter(data, language_code != "eng")
is_eng_avg_rating <- is_eng$average_rating
non_eng_avg_rating <- non_eng$average_rating

ggplot() +
  stat_density(aes(x = is_eng_avg_rating, color = "English titles"), geom = "line", position = "identity") +
  geom_vline(aes(xintercept = mean(is_eng_avg_rating)), linetype = "dashed", color = "red") +
  stat_density(aes(x = non_eng_avg_rating, color = "Non-English titles"), geom = "line", position = "identity") +
  geom_vline(aes(xintercept = mean(non_eng_avg_rating)), linetype = "dashed", color = "darkturquoise") +
  labs(y = "Density", x = "Average rating", title = "PDF of English and non-English books' average ratings") +
  theme(legend.position = "bottom")
```
  
The graph is leading us to the conclusion that the average ratings of both language groups distribute similarly --- approximately normal around the mean, yet denser around the left tail, as we would expected considering the mean rating is very close to 4, and the possible values being 0 to 5. This result reflects the Q-Q plots excellently, with the slight differences with the non-English titles explained by a smaller sample size.

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.B.5. Ratings count and text reviews**

We will now look at the distribution of the text reviews count and the number of ratings predictors.  
Since our data ranges across multiple orders of magnitude, we apply logarithm to the text reviews count and the ratings count. We use `log2()` as suggested on page 57 in the “R for Data Science” book.  

**Text reviews count:**

```{r text reviews density, warning = FALSE, fig.align = "center", fig.width = 6, fig.height = 4}
text_review_count <- log2(data$text_reviews_count)
ggplot(data, aes(x = text_review_count)) +
  geom_density(fill = "grey", color = "blue") +
  labs(y = "Density", x = "log2 text reviews count", title = "PDF of log2 text reviews count")
```

We can see that this distribution looks log normal with a slight skew to the left.

&nbsp;

**The number of ratings:**

```{r ratings count density, fig.align = "center", fig.width = 6, fig.height = 4}
num_of_ratings <- log2(data$ratings_count)
ggplot(data, aes(x = num_of_ratings)) +
  geom_density(fill = "grey", color = "blue") +
  labs(y = "Density", x = "log2 number of ratings", title = "PDF of log2 number of ratings")
```

We can see that this distribution also looks log normal with a skew to the left.  
Both distributions make sense, and it is no surprise that there is a high correlation between those two predictors, as we have shown in the correlation heatmap.

**Note:** Observations with less than 30 ratings have been removed, hence the slightly bigger skew to the left on the second graph.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.B.6. Number of ratings and average rating association**

In order to check the association between the number of ratings the books have and their ratings, I will use two methods. The first method is using a graph, and the second one is using a simple linear regression, which we will apply at the modelling part.

``` {r ratings count and avg, fig.align = "center", fig.width = 8, fig.height = 7}
avg_rating = data$average_rating
num_of_ratings <- log2(data$ratings_count)
ggplot(data, mapping = aes(x = num_of_ratings, y =  avg_rating)) +
  geom_point() + stat_smooth(method = "lm", se = FALSE) +
  labs(y = "Average rating", x = "log2 number of ratings", title = "Linear regression line on number of ratings-average rating scatter plot")
```

We can't determine visually whether the relationship between the two variables is clearly linear or not, hence we will turn to a linear regression model for help in the next part.  

**Note:** Observations with less than 30 ratings have been removed, hence the sharp end on the left.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

***

### Part C | **Modelling**

&nbsp;

In this part we will implement various statistical models and tools, such as linear regression, hypothesis testing etc. in order to find interesting statistical information hidden within our data.

&nbsp;

#### **3.C.1. Simple linear regression**

As we mentioned, we will apply a simple linear regression in order to check the relationship between the `ratings_count` the books have and their `average_rating`.  
We will use our normally scaled dataset (`norm_scaled_data`):

```{r simple linear reg model}
numer_vars <- c("weeks_since_publication", "title_len", "num_pages", "ratings_count", "text_reviews_count", "average_rating")
scaled_numer_vars <- c("scaled_weeks_since_publication", "scaled_title_len", "scaled_num_pages", "scaled_ratings_count", "scaled_text_reviews_count", "average_rating")

numerical_data <- data[, numer_vars]
norm_scaled_numer_data <- norm_scaled_data[, scaled_numer_vars]

simple_lin_reg_model <- lm(average_rating ~ scaled_ratings_count, norm_scaled_numer_data)

summary(simple_lin_reg_model)
```

&nbsp;

**The equation of linear regression is:**

$$\hat{Y_i} = 3.949 + 0.012\cdot{x_{i}^{SRC}}$$

Where the abbreviation stands for the variable name.

We can consider a linear model to be statistically significant when both p-values are less than the pre-determined statistical significance level $\alpha$ = 0.05, which is in fact the case as we can see according to the significance stars.

We have clearly established that there is a statistically significant possitive correlation between the amount of ratings and the average score.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.C.2. Multivariate regression**

We would also like to apply multivariate regression model on all of our numerical variables:

```{r multi linear reg model}
multi_lin_reg_model <- lm(average_rating ~ 
                            scaled_weeks_since_publication +
                            scaled_title_len +
                            scaled_num_pages +
                            scaled_ratings_count +
                            scaled_text_reviews_count,
                          norm_scaled_numer_data)

summary(multi_lin_reg_model)
```

&nbsp;

**The equation of multivariate linear regression is:**

$$\hat{Y_i} = 3.949 + 0.019\cdot{x_{i}^{SWSP}} + 0.047\cdot{x_{i}^{STL}} + 0.05\cdot{x_{i}^{SNP}} + 0.012\cdot{x_{i}^{SRC}} + 0.001\cdot{x_{i}^{STRC}}$$

Where the abbreviations stand for variable names.  
  
We have clearly established that there is a statistically significant possitive correlation between

* The number of pages
* The book's title length
* The weeks passed since publication
* The ratings count

and the average score. Unsurprisingly, the `text_reviews_count` variable got such a small weight as it is highly correlated with the `ratings_count` variable (as we've seen on our correlation heatmap), hence has almost the same effect on the dependent variable `average_rating`, which renders it redundant.  
The result also leads us to the conclusion that our decision to add the `title_len` variable has paid off as indicated by it's relatively large weight and high significance level in our model.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.C.3. Models evaluation and comparison**

We can use the `anova()` function to get additional information about our models --- an **ANOVA** (**Analysis of Variance**) table:

```{r anova}
anova(multi_lin_reg_model)
```

We can also use it to compare our models:

```{r model comparison}
anova(simple_lin_reg_model, multi_lin_reg_model)
```

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.C.4. Variable selection using all-subsets regression**

We've just decided which model to use and start to have a sense of the importance of each variable thanks to our ANOVA tables. Although this step usually belongs to the pre-processing phase, we will turn to it now as we wanted to first model using our "original" desired variables.
We can perform variable selection by, for example, using all-subsets regression:

```{r variables selection, warning = FALSE, fig.align = "center", fig.width = 8, fig.height = 8}
attach(norm_scaled_numer_data)

leaps <- regsubsets(average_rating ~ 
                      scaled_weeks_since_publication +
                      scaled_title_len +
                      scaled_num_pages +
                      scaled_ratings_count +
                      scaled_text_reviews_count,
                    data = norm_scaled_numer_data,
                    nbest = 1,
                    method = "exhaustive")

plot(leaps, scale = "r2")
title("A table of models showing the variable composition in each,\nordered by the value of selection statistic R-squared")
```

As we can see, our model/feature selection table precisely represents our recent conclusion: the `text_reviews_count` variable is highly correlated with the `ratings_count` variable, hence has almost the same effect on the dependent variable `average_rating`, which renders it redundant.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

#### **3.C.5. Hypothesis testing**

Our hypothesis is that the mean `average_rating` of titles whose publication dates are **earlier** than the *goodreads* website launch date (January 2006) is different than of those whose publication dates are post-launch.

* $H_0: \mu_{before} = \mu_{after}$
* $H_1: \mu_{before} \neq \mu_{after}$
* $\alpha = 0.05$
* **Test statistic**: $t = \frac{\bar{X}_{before} - \bar{X}_{after}}{\sqrt{ \frac{S_{before}^2}{n_{before}} + \frac{S_{after}^2}{n_{after}}}}$  
  where:
  + $\bar{X}_{before}$ and $\bar{X}_{after}$ represent the mean values of the groups, respectively.
  + $n_{before}$ and $n_{after}$ represent the sizes of the group A and B, respectively.
  + $S_{before}$ and $S_{after}$ represent the standard deviations of the groups, respectively.
* The test's degrees of freedom are estimated as:
  $df = \frac{\frac{S_{before}^2}{n_{before}}+ \frac{S_{after}^2}{n_{after}^2}}{\frac{S_{before}^4}{n_{before}^2(n_{after}-1)} + \frac{S_{after}^4}{n_{after}^2(n_{after}-1)}}$
  
Now, let's perform the test:  

```{r t test}
update_launch_diff <- as.numeric(as.Date("09/03/2020", format = "%d/%m/%Y") - as.Date("01/01/2006", format = "%d/%m/%Y")) / 7

weeks_since_publication <- data$weeks_since_publication

ratings_before_launch <- data[weeks_since_publication > update_launch_diff, "average_rating"]
ratings_after_launch <- data[weeks_since_publication <= update_launch_diff, "average_rating"]

t.test(x = ratings_before_launch,
       y = ratings_after_launch,
       alternative = "two.sided",
       var.equal = FALSE)
```

&nbsp;

In other words, the alternative hypothesis $H_1: \mu_{before} - \mu_{after} \neq 0$ is **true** with a p-value of 0.000009266 < $\alpha$ = 0.05, showing that the `average_rating` means of books published before and after the *goodreads* launch are in fact different, which might suggest that titles without a pre-existing status quo around them are rated more objectively, meaning that thanks to the website, readers are exposed to a more accurate and less biased rating of new publications.

&nbsp;

```{r, results = 'asis', echo = FALSE}
cat("\\newpage")
```

***

## Phase 4 | **Communicate**

***

**In conclusion:**

Our goal was to extract as much interesting statistical information as possible, while putting an emphasis on quality by:

* Maintaining a strict, structured and professional data science workflow.
* Focusing on clean data via careful management, maintanance and processing.

In order to reach this goal, we have thoroughly and methodically cleaned up and pre-processed our data, used various visualization techniques to obtain a better understanding and interesting insights about the data, and implemented various statistical models and tools, such as linear regression and hypothesis testing, in order to deduce conclusions about the relations between different variables and their effects on the average score.  
 
Finally, our analysis has kindly invited, and left a room for, further research in various aspects related to the publications’ ratings. We acknowledge the fact that our research has its limitations, but we also sincerely hope it could be of use for others.

&nbsp;
